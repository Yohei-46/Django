import requests
from bs4 import BeautifulSoup

'''
race_idã®å‘½åè¦å‰‡
IDã¯12æ¡ã§æ§‹æˆã€‚
ä¾‹ï¼š202505020204

å¹´ï¼ˆYYYY)ï¼šã€Œ2025ã€/é–‹å‚¬å¹´
å ´æ‰€ã‚³ãƒ¼ãƒ‰ï¼šã€Œ05ã€/æ±äº¬ç«¶é¦¬å ´ï¼ˆPLACE_CODE_MAPã‚ˆã‚Šï¼‰
é–‹å‚¬å›ï¼šã€Œ02ã€/é–‹å‚¬2å›
é–‹å‚¬æ—¥ï¼šã€Œ02ã€/é–‹å‚¬2æ—¥ç›®
ãƒ¬ãƒ¼ã‚¹ç•ªå·ï¼šã€Œ04ã€/ç¬¬4ãƒ¬ãƒ¼ã‚¹
'''

race_id = "202505020106"
url = f"https://race.netkeiba.com/race/result.html?race_id={race_id}"

headers = {
    "User-Agent": "Mozilla/5.0"
}

try:
    response = requests.get(url, headers=headers, timeout=10)
    response.raise_for_status()
except requests.exceptions.RequestException as e:
    print(f"âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¤±æ•—: {e}")
    exit()

# è‡ªå‹•åˆ¤åˆ¥ã•ã‚ŒãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ç”¨
response.encoding = response.apparent_encoding
print("ğŸ“„ Response encoding:", response.encoding)

html = response.text
soup = BeautifulSoup(html, "html.parser")

# ãƒ‡ãƒãƒƒã‚°ç”¨ã«ä¿å­˜
with open("debug.html", "w", encoding="utf-8") as f:
    f.write(soup.prettify())

# çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚»ãƒ¬ã‚¯ã‚¿å€™è£œã‚’è¤‡æ•°è©¦ã™
result_table = (
    soup.select_one("#All_Result_Table") or
    soup.select_one(".RaceResultTable") or
    soup.select_one(".RaceTable01")
)

if result_table:
    print("âœ… ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å–å¾—ã§ãã¾ã—ãŸã€‚")
else:
    print("âŒ ãƒ¬ãƒ¼ã‚¹çµæœãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚debugæƒ…å ±ã‚’ä¿å­˜ã—ã¾ã™ã€‚")
    with open("error_debug.html", "w", encoding="utf-8") as f:
        f.write(soup.prettify())